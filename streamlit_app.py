import streamlit as st
import os
from langchain_openai import ChatOpenAI
from langchain_google_genai import ChatGoogleGenerativeAI
from dotenv import load_dotenv
from data import TOPICS  # –ù–æ–≤—ã–π —Ñ–æ—Ä–º–∞—Ç —Å—Ö–µ–º
from prompts import TUTOR_PROMPT, LEARN_MODE_PROMPT, FEEDBACK_PROMPT
from utils import format_schema, format_chat_to_markdown, get_chat_filename

load_dotenv()

st.set_page_config(page_title="–ú–∞—Ç–µ–º–∞—Ç–∏—á–µ—Å–∫–∏–π –ø–æ–º–æ—â–Ω–∏–∫ AI", page_icon="üßÆ", layout="wide")

# ============= –ò–ù–ò–¶–ò–ê–õ–ò–ó–ê–¶–ò–Ø –ê–ì–ï–ù–¢–ê =============

@st.cache_resource
def init_bot(model_choice, yandex_key, gemini_key):
    """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ—Ç –ø–æ–º–æ—â–Ω–∏–∫–∞ - –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç –ø—Ä—è–º–æ–π LLM –±–µ–∑ –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–æ–≤"""
    if model_choice == "YandexGPT 5.1 Pro":
        llm = ChatOpenAI(api_key=yandex_key, base_url="http://localhost:8520/v1",
                        model="yandexgpt/latest", temperature=0.3)
    else:
        llm = ChatGoogleGenerativeAI(model="gemini-2.5-flash", google_api_key=gemini_key,
                                    temperature=0.3, convert_system_message_to_human=True)

    return llm

@st.cache_resource
def init_tutor(model_choice, yandex_key, gemini_key):
    """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ—Ç —Ç—å—é—Ç–æ—Ä–∞ –¥–ª—è Study Mode - –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç –ø—Ä—è–º–æ–π LLM –±–µ–∑ –∞–≥–µ–Ω—Ç–∞"""
    if model_choice == "YandexGPT 5.1 Pro":
        llm = ChatOpenAI(api_key=yandex_key, base_url="http://localhost:8520/v1",
                        model="yandexgpt/latest", temperature=0.6)
    else:
        # –ò—Å–ø–æ–ª—å–∑—É–µ–º Gemini –±–µ–∑ thinking mode –¥–ª—è –±–æ–ª–µ–µ –±—ã—Å—Ç—Ä—ã—Ö –æ—Ç–≤–µ—Ç–æ–≤
        llm = ChatGoogleGenerativeAI(
            model="gemini-2.5-flash",
            google_api_key=gemini_key,
            temperature=0.6,
            convert_system_message_to_human=True,
            model_kwargs={
                "thinking_config": {
                    "thinking_mode": "DISABLED"
                }
            }
        )

    return llm

# ============= –§–£–ù–ö–¶–ò–ò =============
# (–°—Ç–∞—Ä—ã–µ —Ñ—É–Ω–∫—Ü–∏–∏ —É–¥–∞–ª–µ–Ω—ã - –∏—Å–ø–æ–ª—å–∑—É–µ–º –ø—Ä–æ–º–ø—Ç-–ø–æ–¥—Ö–æ–¥)


# ============= –ò–ù–ò–¶–ò–ê–õ–ò–ó–ê–¶–ò–Ø –°–û–°–¢–û–Ø–ù–ò–Ø =============

if "mode" not in st.session_state:
    # –ü–æ —É–º–æ–ª—á–∞–Ω–∏—é —Ä–µ–∂–∏–º –∏–∑—É—á–µ–Ω–∏—è —Ç–µ–º—ã
    st.session_state.mode = "learn"
if "messages" not in st.session_state:
    st.session_state.messages = []

# –î–ª—è —Ä–µ–∂–∏–º–∞ –æ–±—É—á–µ–Ω–∏—è
if "current_topic" not in st.session_state:
    st.session_state.current_topic = None
if "study_mode_initialized" not in st.session_state:
    st.session_state.study_mode_initialized = False
if "needs_feedback" not in st.session_state:
    st.session_state.needs_feedback = False

# ============= UI =============

# –ó–∞–≥–æ–ª–æ–≤–æ–∫ –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç —Ä–µ–∂–∏–º–∞
if st.session_state.mode == "learn":
    st.title("üéì Study Mode")
    st.markdown("*–¢–≤–æ–π –ø–µ—Ä—Å–æ–Ω–∞–ª—å–Ω—ã–π —Ç—å—é—Ç–æ—Ä*")
    st.markdown("---")
else:
    st.title("üßÆ –ú–∞—Ç–µ–º–∞—Ç–∏—á–µ—Å–∫–∏–π –ø–æ–º–æ—â–Ω–∏–∫ AI")
    st.markdown("*–ü–æ–º–æ–≥–∞—é —É—á–∏—Ç—å –º–∞—Ç–µ–º–∞—Ç–∏–∫—É!*")
    st.markdown("---")


# ============= SIDEBAR =============

with st.sidebar:
    st.header("‚öôÔ∏è –ù–∞—Å—Ç—Ä–æ–π–∫–∏")
    
    # –í—ã–±–æ—Ä —Ä–µ–∂–∏–º–∞ —Ä–∞–±–æ—Ç—ã
    mode = st.radio(
        "üéØ –†–µ–∂–∏–º —Ä–∞–±–æ—Ç—ã:",
        ["learn", "study"],
        format_func=lambda x: {"learn": "üìö –ò–∑—É—á–∏—Ç—å —Ç–µ–º—É", "study": "üéì Study Mode (–¢—å—é—Ç–æ—Ä)"}[x],
        key="mode_selector"
    )

    # –†–µ–∂–∏–º –Ω–µ –º–µ–Ω—è–µ—Ç—Å—è –≤ —Ä–∞–Ω—Ç–∞–π–º–µ (–æ—á–∏—â–∞–µ–º —Å–æ–æ–±—â–µ–Ω–∏—è –∏ —Å–æ—Å—Ç–æ—è–Ω–∏–µ)
    if mode != st.session_state.mode:
        st.session_state.mode = mode
        st.session_state.messages = []
        st.session_state.current_topic = None
        st.session_state.study_mode_initialized = False
        st.session_state.needs_feedback = False
    
    st.markdown("---")
    
    # –í—ã–±–æ—Ä –º–æ–¥–µ–ª–∏
    model_choice = st.selectbox("ü§ñ AI –ú–æ–¥–µ–ª—å", ["Google Gemini 2.5 Flash", "YandexGPT 5.1 Pro"])
    
    if model_choice == "YandexGPT 5.1 Pro":
        yandex_api_key = st.text_input("API –∫–ª—é—á", value=os.getenv("YANDEX_API_KEY", ""), type="password")
        gemini_api_key = ""
    else:
        gemini_api_key = st.text_input("Google API –∫–ª—é—á", value=os.getenv("GOOGLE_API_KEY", ""), type="password")
        yandex_api_key = ""
        st.markdown("[–ü–æ–ª—É—á–∏—Ç—å –∫–ª—é—á ‚Üí](https://aistudio.google.com/apikey)")
    
    st.markdown("---")

    # –†–ï–ñ–ò–ú-–ó–ê–í–ò–°–ò–ú–´–ô –ö–û–ù–¢–ï–ù–¢
    if mode == "learn":
        # –†–µ–∂–∏–º –∏–∑—É—á–µ–Ω–∏—è —Ç–µ–º—ã
        st.header("üìö –í—ã–±–µ—Ä–∏ —Ç–µ–º—É")
        for topic_id, topic_data in TOPICS.items():
            if st.button(topic_data['title'], key=f"topic_{topic_id}", use_container_width=True):
                st.session_state.current_topic = topic_id
                st.session_state.needs_feedback = False  # –°–±—Ä–∞—Å—ã–≤–∞–µ–º –ø—Ä–∏ –≤—ã–±–æ—Ä–µ –Ω–æ–≤–æ–π —Ç–µ–º—ã

                # –ü—Ä–∏–≤–µ—Ç—Å—Ç–≤–µ–Ω–Ω–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ —Å –ø–ª–∞–Ω–æ–º —É—Ä–æ–∫–∞
                welcome_message = f"**{topic_data['title']}**\n\n{topic_data.get('description', '')}\n\n"

                # –î–æ–±–∞–≤–ª—è–µ–º –ø–ª–∞–Ω, –µ—Å–ª–∏ –æ–Ω –µ—Å—Ç—å
                if 'plan' in topic_data:
                    welcome_message += f"{topic_data['plan']}\n\n"

                welcome_message += "–ì–æ—Ç–æ–≤? –ü–æ–µ—Ö–∞–ª–∏! üöÄ"

                st.session_state.messages = [{
                    "role": "assistant",
                    "content": welcome_message
                }]
                st.rerun()
    else:
        # Study Mode - —Å–≤–æ–±–æ–¥–Ω—ã–π —Ç—å—é—Ç–æ—Ä
        st.header("üéì Study Mode")
        st.markdown("*–ó–∞–¥–∞–π –ª—é–±–æ–π –≤–æ–ø—Ä–æ—Å –ø–æ —à–∫–æ–ª—å–Ω—ã–º –ø—Ä–µ–¥–º–µ—Ç–∞–º*")
        st.markdown("---")
        st.markdown("**–ü—Ä–∏–º–µ—Ä—ã –≤–æ–ø—Ä–æ—Å–æ–≤:**")
        st.markdown("- –ü–æ–º–æ–≥–∏ —Ä–∞–∑–æ–±—Ä–∞—Ç—å—Å—è —Å –¥—Ä–æ–±—è–º–∏")
        st.markdown("- –û–±—ä—è—Å–Ω–∏ –∫–≤–∞–¥—Ä–∞—Ç–Ω—ã–µ —É—Ä–∞–≤–Ω–µ–Ω–∏—è")
        st.markdown("- –†–µ—à–∏ –∑–∞–¥–∞—á—É –ø–æ —Ñ–∏–∑–∏–∫–µ")

        if st.button("üÜï –ù–∞—á–∞—Ç—å –Ω–æ–≤—É—é —Ç–µ–º—É", use_container_width=True):
            st.session_state.messages = []
            st.session_state.study_mode_initialized = False
            st.rerun()
    
    st.markdown("---")
    
    if st.button("üóëÔ∏è –ù–∞—á–∞—Ç—å –∑–∞–Ω–æ–≤–æ", use_container_width=True):
        st.session_state.messages = []
        st.session_state.current_topic = None
        st.session_state.study_mode_initialized = False
        st.session_state.needs_feedback = False
        st.rerun()

    # –ö–Ω–æ–ø–∫–∞ —ç–∫—Å–ø–æ—Ä—Ç–∞ –¥–∏–∞–ª–æ–≥–∞
    if len(st.session_state.messages) > 0:
        st.markdown("---")
        st.markdown("**üíæ –≠–∫—Å–ø–æ—Ä—Ç –¥–∏–∞–ª–æ–≥–∞**")

        # –ü–æ–ª—É—á–∞–µ–º –Ω–∞–∑–≤–∞–Ω–∏–µ —Ç–µ–º—ã –µ—Å–ª–∏ –µ—Å—Ç—å
        topic_title = None
        if st.session_state.mode == "learn" and st.session_state.current_topic:
            topic_title = TOPICS[st.session_state.current_topic].get('title', '–¢–µ–º–∞')

        # –§–æ—Ä–º–∞—Ç–∏—Ä—É–µ–º –¥–∏–∞–ª–æ–≥
        chat_markdown = format_chat_to_markdown(st.session_state.messages, topic_title)
        filename = get_chat_filename(topic_title, "md")

        # –ö–Ω–æ–ø–∫–∞ —Å–∫–∞—á–∏–≤–∞–Ω–∏—è
        st.download_button(
            label="üì• –°–∫–∞—á–∞—Ç—å –¥–∏–∞–ª–æ–≥ (Markdown)",
            data=chat_markdown,
            file_name=filename,
            mime="text/markdown",
            use_container_width=True
        )

# ============= –ü–†–û–í–ï–†–ö–ê API =============

current_key = yandex_api_key if model_choice == "YandexGPT 5.1 Pro" else gemini_api_key

if not current_key:
    st.warning(f"‚ö†Ô∏è –í–≤–µ–¥–∏—Ç–µ API –∫–ª—é—á –≤ –Ω–∞—Å—Ç—Ä–æ–π–∫–∞—Ö —Å–ª–µ–≤–∞")
    st.info("üí° –î–ª—è –Ω–∞—á–∞–ª–∞ –ø–æ–ª—É—á–∏—Ç–µ –±–µ—Å–ø–ª–∞—Ç–Ω—ã–π –∫–ª—é—á Gemini")
    st.stop()

# ============= –û–°–ù–û–í–ù–û–ô –ò–ù–¢–ï–†–§–ï–ô–° =============

# –ü–æ–∫–∞–∑—ã–≤–∞–µ–º —Ä–µ–∂–∏–º
mode_badges = {
    "learn": "üìö –ò–∑—É—á–∏—Ç—å —Ç–µ–º—É",
    "study": "üéì Study Mode (–¢—å—é—Ç–æ—Ä)"
}
st.info(f"**–¢–µ–∫—É—â–∏–π —Ä–µ–∂–∏–º:** {mode_badges[st.session_state.mode]}")

# –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è Study Mode - –ø–æ–∫–∞–∑—ã–≤–∞–µ–º –ø—Ä–∏–≤–µ—Ç—Å—Ç–≤–∏–µ –ø—Ä–∏ –ø–µ—Ä–≤–æ–º –≤—Ö–æ–¥–µ
if st.session_state.mode == "study" and not st.session_state.study_mode_initialized and len(st.session_state.messages) == 0:
    welcome_message = """–ü—Ä–∏–≤–µ—Ç! –Ø –ø–æ–º–æ–≥—É —Ç–µ–±–µ —Ä–∞–∑–æ–±—Ä–∞—Ç—å—Å—è —Å –ª—é–±–æ–π —Ç–µ–º–æ–π üìö

–ß—Ç–æ–±—ã –Ω–∞—à–µ –∑–∞–Ω—è—Ç–∏–µ –±—ã–ª–æ –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ –ø–æ–ª–µ–∑–Ω—ã–º, —Å–∫–∞–∂–∏, –ø–æ–∂–∞–ª—É–π—Å—Ç–∞:

1. **–í –∫–∞–∫–æ–º —Ç—ã –∫–ª–∞—Å—Å–µ?** (–∏–ª–∏ —Å–∫–æ–ª—å–∫–æ —Ç–µ–±–µ –ª–µ—Ç?)
2. **–ö–∞–∫—É—é —Ç–µ–º—É —Ö–æ—á–µ—à—å –∏–∑—É—á–∏—Ç—å?** (–Ω–∞–ø—Ä–∏–º–µ—Ä, –ø—Ä–æ–ø–æ—Ä—Ü–∏–∏, –¥—Ä–æ–±–∏, —É—Ä–∞–≤–Ω–µ–Ω–∏—è)
3. **–ö–∞–∫–∞—è —É —Ç–µ–±—è —Ü–µ–ª—å?** –¢—ã —Ö–æ—á–µ—à—å –ø—Ä–æ—Å—Ç–æ –ø–æ–Ω—è—Ç—å —Ç–µ–º—É, —Ä–µ—à–∏—Ç—å –∫–æ–Ω–∫—Ä–µ—Ç–Ω—É—é –∑–∞–¥–∞—á—É –∏–ª–∏, –º–æ–∂–µ—Ç –±—ã—Ç—å, –≥–æ—Ç–æ–≤–∏—Ç—å—Å—è –∫ –∫–æ–Ω—Ç—Ä–æ–ª—å–Ω–æ–π?"""

    st.session_state.messages.append({"role": "assistant", "content": welcome_message})
    st.session_state.study_mode_initialized = True

# –ò—Å—Ç–æ—Ä–∏—è —Å–æ–æ–±—â–µ–Ω–∏–π
for idx, message in enumerate(st.session_state.messages):
    with st.chat_message(message["role"]):
        # –†–µ–Ω–¥–µ—Ä–∏–º —Å–æ–¥–µ—Ä–∂–∏–º–æ–µ —Å–æ–æ–±—â–µ–Ω–∏—è, –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞—è –∫—Ä—É–ø–Ω—ã–π LaTeX
        st.markdown(message["content"], unsafe_allow_html=True)

# –û–±—Ä–∞–±–æ—Ç–∫–∞ –æ–±—ã—á–Ω–æ–≥–æ –≤–≤–æ–¥–∞ —Å –∫–ª–∞–≤–∏–∞—Ç—É—Ä—ã
question = st.chat_input("–ù–∞–ø–∏—à–∏ —Å–≤–æ–π –≤–æ–ø—Ä–æ—Å –∏–ª–∏ –æ—Ç–≤–µ—Ç...")
show_user_message = True

if question:
    # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Å–æ–æ–±—â–µ–Ω–∏–µ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
    st.session_state.messages.append({"role": "user", "content": question})
    with st.chat_message("user"):
        st.markdown(question)

    with st.chat_message("assistant"):
        with st.spinner("ü§î –î—É–º–∞—é..."):
            # –û–±—Ä–∞–±–æ—Ç–∫–∞ –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç —Ä–µ–∂–∏–º–∞
            if st.session_state.mode == "study":
                # Study Mode - —Å–≤–æ–±–æ–¥–Ω—ã–π —Ç—å—é—Ç–æ—Ä (–ø—Ä—è–º–æ–π –≤—ã–∑–æ–≤ LLM –±–µ–∑ –∞–≥–µ–Ω—Ç–∞)
                tutor_llm = init_tutor(model_choice, yandex_api_key, gemini_api_key)

                # –§–æ—Ä–º–∏—Ä—É–µ–º –ø–æ–ª–Ω—ã–π –ø—Ä–æ–º–ø—Ç —Å –∏—Å—Ç–æ—Ä–∏–µ–π —á–∞—Ç–∞
                chat_history = "\n".join([
                    f"{'–£—á–µ–Ω–∏–∫' if msg['role'] == 'user' else '–¢—å—é—Ç–æ—Ä'}: {msg['content']}"
                    for msg in st.session_state.messages[-5:]  # –ü–æ—Å–ª–µ–¥–Ω–∏–µ 5 —Å–æ–æ–±—â–µ–Ω–∏–π –¥–ª—è –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞
                ])

                # –§–æ—Ä–º–∏—Ä—É–µ–º –ø–æ–ª–Ω–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ –¥–ª—è LLM
                full_prompt = TUTOR_PROMPT.replace("{chat_history}", chat_history).replace("{input}", question)

                try:
                    response_obj = tutor_llm.invoke(full_prompt)
                    response = response_obj.content if hasattr(response_obj, 'content') else str(response_obj)
                except Exception as e:
                    print(f"Tutor error: {e}")
                    response = "–ò–∑–≤–∏–Ω–∏, –ø—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞. –ü–æ–ø—Ä–æ–±—É–π –ø–µ—Ä–µ—Ñ–æ—Ä–º—É–ª–∏—Ä–æ–≤–∞—Ç—å –≤–æ–ø—Ä–æ—Å."

                st.markdown(response)
                st.session_state.messages.append({"role": "assistant", "content": response})

            elif st.session_state.current_topic is None:
                response = "–ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –≤—ã–±–µ—Ä–∏ —Ç–µ–º—É –∏–∑ —Å–ø–∏—Å–∫–∞ —Å–ª–µ–≤–∞! üëà"
                st.markdown(response)
                st.session_state.messages.append({"role": "assistant", "content": response})
            else:
                # Learn Mode - –∏—Å–ø–æ–ª—å–∑—É–µ–º LEARN_MODE_PROMPT —Å–æ —Å—Ö–µ–º–æ–π —Ç–µ–º—ã
                topic = TOPICS[st.session_state.current_topic]
                learn_llm = init_tutor(model_choice, yandex_api_key, gemini_api_key)

                # –§–æ—Ä–º–∞—Ç–∏—Ä—É–µ–º —Å—Ö–µ–º—É —Ç–µ–º—ã
                schema = format_schema(topic)

                # –§–æ—Ä–º–∏—Ä—É–µ–º –∏—Å—Ç–æ—Ä–∏—é —á–∞—Ç–∞
                chat_history = "\n".join([
                    f"{'–£—á–µ–Ω–∏–∫' if msg['role'] == 'user' else '–¢—å—é—Ç–æ—Ä'}: {msg['content']}"
                    for msg in st.session_state.messages[-5:]  # –ü–æ—Å–ª–µ–¥–Ω–∏–µ 5 —Å–æ–æ–±—â–µ–Ω–∏–π
                ])

                # –§–æ—Ä–º–∏—Ä—É–µ–º –ø–æ–ª–Ω—ã–π –ø—Ä–æ–º–ø—Ç
                full_prompt = LEARN_MODE_PROMPT.replace("{schema}", schema).replace("{chat_history}", chat_history).replace("{input}", question)

                try:
                    response_obj = learn_llm.invoke(full_prompt)
                    response = response_obj.content if hasattr(response_obj, 'content') else str(response_obj)
                except Exception as e:
                    print(f"Learn mode error: {e}")
                    response = "–ò–∑–≤–∏–Ω–∏, –ø—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞. –ü–æ–ø—Ä–æ–±—É–π –ø–µ—Ä–µ—Ñ–æ—Ä–º—É–ª–∏—Ä–æ–≤–∞—Ç—å –≤–æ–ø—Ä–æ—Å."

                # –ü—Ä–æ–≤–µ—Ä—è–µ–º –º–∞—Ä–∫–µ—Ä –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è —É—Ä–æ–∫–∞
                # LLM –¥–æ–±–∞–≤–ª—è–µ—Ç [–£–†–û–ö_–ó–ê–í–ï–†–®–ï–ù] —Ç–æ–ª—å–∫–æ –ø–æ—Å–ª–µ –ø–æ–∫–∞–∑–∞ –∫–æ–Ω—Å–ø–µ–∫—Ç–∞
                if "[–£–†–û–ö_–ó–ê–í–ï–†–®–ï–ù]" in response:
                    st.session_state.needs_feedback = True
                    # –£–±–∏—Ä–∞–µ–º –º–∞—Ä–∫–µ—Ä –∏–∑ –æ—Ç–æ–±—Ä–∞–∂–∞–µ–º–æ–≥–æ —Ç–µ–∫—Å—Ç–∞ (–æ–Ω —Å–ª—É–∂–µ–±–Ω—ã–π)
                    response = response.replace("[–£–†–û–ö_–ó–ê–í–ï–†–®–ï–ù]", "").strip()

                st.markdown(response)
                st.session_state.messages.append({"role": "assistant", "content": response})

                # –ï—Å–ª–∏ –Ω—É–∂–µ–Ω —Ñ–∏–¥–±–µ–∫, –ø–æ–∫–∞–∑—ã–≤–∞–µ–º –µ–≥–æ –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏
                if st.session_state.needs_feedback:
                    # –§–æ—Ä–º–∏—Ä—É–µ–º –∏—Å—Ç–æ—Ä–∏—é –¥–ª—è —Ñ–∏–¥–±–µ–∫–∞ (–≤–µ—Å—å —Ä–∞–∑–≥–æ–≤–æ—Ä)
                    full_chat_history = "\n".join([
                        f"{'–£—á–µ–Ω–∏–∫' if msg['role'] == 'user' else '–¢—å—é—Ç–æ—Ä'}: {msg['content']}"
                        for msg in st.session_state.messages
                    ])

                    # –§–æ—Ä–º–∏—Ä—É–µ–º –ø—Ä–æ–º–ø—Ç –¥–ª—è —Ñ–∏–¥–±–µ–∫–∞
                    feedback_prompt = FEEDBACK_PROMPT.replace(
                        "{topic_title}", topic.get('title', '')
                    ).replace(
                        "{topic_description}", topic.get('description', '')
                    ).replace(
                        "{chat_history}", full_chat_history
                    ).replace(
                        "{final_summary}", topic.get('summary', '')
                    )

                    try:
                        feedback_obj = learn_llm.invoke(feedback_prompt)
                        feedback = feedback_obj.content if hasattr(feedback_obj, 'content') else str(feedback_obj)

                        # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º —Ñ–∏–¥–±–µ–∫
                        st.markdown("\n\n---\n\n")
                        st.markdown(feedback)
                        st.session_state.messages.append({"role": "assistant", "content": f"\n\n---\n\n{feedback}"})

                        # –°–±—Ä–∞—Å—ã–≤–∞–µ–º —Ñ–ª–∞–≥
                        st.session_state.needs_feedback = False
                    except Exception as e:
                        print(f"Feedback error: {e}")

# –í—Å—Ç–∞–≤–ª—è–µ–º CSS, —á—Ç–æ–±—ã —É–≤–µ–ª–∏—á–∏—Ç—å —Ä–∞–∑–º–µ—Ä —Ñ–æ—Ä–º—É–ª
st.markdown(
    """
    <style>
    .stMarkdown .katex {
        font-size: 1.5em !important;
    }
    </style>
    """,
    unsafe_allow_html=True,
)